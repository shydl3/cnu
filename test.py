import asyncio
import json
import os.path
from os.path import splitext

from playwright.async_api import async_playwright
import aiohttp

main_page = "http://cnu.cc"
login_page = "http://www.cnu.cc/login"
fav_page = "http://www.cnu.cc/users/favorites"
fav_subpage = "http://www.cnu.cc/users/favorites?page=1"
wechat_login = "http://www.cnu.cc/auth/wechat-login/%7BisLogin%7D"

cookie_file = "auth_storage.json"

desktop_path = os.path.join(os.path.expanduser('~'), 'Desktop', 'CNU')

async def login(p):
    browser = await p.chromium.launch(headless=False)

    if os.path.exists(cookie_file):
        context = await browser.new_context(locale="zh-CN", storage_state=cookie_file)
        print("âœ… å·²åŠ è½½ä¿å­˜çš„ Cookie ç™»å½•çŠ¶æ€")
    else:
        context = await browser.new_context(locale="zh-CN")
        print("ğŸš« æœªæ‰¾åˆ° Cookieï¼Œè¯·æ‰«ç ç™»å½•")

    page = await context.new_page()
    await page.goto(main_page)
    if not await page.locator("#userNav").is_visible(timeout=10000):
        print("ğŸ”’ Cookie æ— æ•ˆæˆ–æœªç™»å½•ï¼Œè¿›å…¥æ‰«ç ç™»å½•æµç¨‹..")
        await page.goto(wechat_login)

        try:
            await page.wait_for_selector("#userNav", timeout=120000)
            print("âœ… ç™»å½•æˆåŠŸï¼ä¿å­˜ Cookie...")
            await context.storage_state(path=cookie_file)
            await page.click("#userNav")

        except TimeoutError:
            print("âŒ ç™»å½•è¶…æ—¶ï¼Œæœªèƒ½å®Œæˆæ‰«ç ")
            await browser.close()
            return None, None

    else:
        print("âœ… å·²ç™»å½•")

    return context, page


async def extract_posts(page):
    await page.wait_for_selector(".work-thumbnail", timeout=10000)
    items = page.locator(".work-thumbnail")
    count = await items.count()
    print(f"âœ… æœ¬é¡µå…±æœ‰ {count} ä¸ªæ”¶è—ä½œå“")

    results = []

    for i in range(count):
        item = items.nth(i).locator("a.thumbnail")
        href = await item.get_attribute("href")
        title = await item.locator(".title").text_content()
        results.append({
            "title": title.strip() if title else "(æ— æ ‡é¢˜)",
            "url": href.strip() if href else "#"
        })

    return results


async def get_total_pages(page):
    await page.wait_for_selector("ul.pagination", timeout=10000)
    li_count = await page.locator(".pagination > li").count()
    page_count = li_count - 2

    return page_count

async def save_images_from_posts(page, post_url, title):
    print(f"ğŸ“¥ å¼€å§‹å¤„ç†ï¼š{title} - {post_url}")
    await page.goto(post_url)

    await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
    await asyncio.sleep(2)

    img_json = await page.evaluate("document.getElementById('imgs_json')?.innerText")
    if not img_json:
        print("âš ï¸ æ— æ³•æ‰¾åˆ°å›¾ç‰‡ JSON æ•°æ®ï¼Œè·³è¿‡..")
        return

    try:
        img_list = json.loads(img_json)
    except Exception as e:
        print(f"âŒ JSON è§£ç å¤±è´¥: {e}")
        return

    save_path = os.path.join(desktop_path, title)
    # print(save_path)
    os.makedirs(save_path, exist_ok=True)

    async with aiohttp.ClientSession() as session:
        for idx, img in enumerate(img_list):
            img_path = img.get("img")
            if not img_path:
                print(f"skipping {idx}")
                continue
            img_url = f"http://imgoss.cnu.cc/{img_path}?x-oss-process=style/content"
            ext = os.path.splitext(img_path)[-1].split("?")[0] or ".jpg"
            file_name = os.path.join(save_path, f"{idx + 1}{ext}")

            try:
                async with session.get(img_url) as resp:
                    if resp.status == 200:
                        with open(file_name, 'wb') as f:
                            f.write(await resp.read())
                        print(f"âœ… å·²ä¿å­˜ï¼š{file_name}")
                    else:
                        print(f"âŒ å›¾ç‰‡è¯·æ±‚å¤±è´¥: {img_url}")
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}")

        print(f"ğŸ‰ å®Œæˆï¼š{title}")


async def process_fav(page):
    await page.click("#userNav")
    print("ğŸ”„ æ­£åœ¨è·å–æ”¶è—åˆ—è¡¨..")
    await page.locator("#favLi").click(timeout=10000)

    page_count = await get_total_pages(page)
    print(f"âœ… æ”¶è—å¤¹å…±æœ‰ {page_count} é¡µ")

    for page_num in range(1, page_count+1):
        url = f"http://www.cnu.cc/users/favorites?page={page_num}"
        print(f"ğŸ”„ æ­£åœ¨è®¿é—®ç¬¬ {page_num} é¡µ: {url}")
        await page.goto(url)
        posts_list = await extract_posts(page)
        for post in posts_list:
            # print(post)
            post_title = post["title".replace("/", "_").replace("\\", "_")]
            post_url = post["url"]

            if not post_url.startswith("http"):
                post_url = "http://www.cnu.cc" + post_url
            await save_images_from_posts(page, post_url, post_title)

            # exit(0)


async def main():
    async with async_playwright() as p:
        context, page = await login(p)
        if context and page:
            await process_fav(page)

            print("ğŸ€ æµ‹è¯•ç»“æŸ")

            await asyncio.Event().wait()  # ä¿æŒçª—å£æ‰“å¼€


asyncio.run(main())